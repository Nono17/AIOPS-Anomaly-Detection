,LineId,YMD,Time,Type,Component,Content
0,1,2021-03-29,"23:58:12,322",INFO,org.apache.hadoop.hdfs.server.datanode.DataNode,STARTUP_MSG:
1,2,2021-03-29,"23:58:12,452",INFO,org.apache.hadoop.hdfs.server.datanode.DataNode,"registered UNIX signal handlers for [TERM, HUP, INT]"
2,3,2021-03-29,"23:58:19,524",INFO,org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker,Scheduling a check for [DISK]file:/home/hadoop3/hadoop/tmp/dfs/data
3,4,2021-03-29,"23:58:21,891",INFO,org.apache.hadoop.metrics2.impl.MetricsConfig,Loaded properties from hadoop-metrics2.properties
4,5,2021-03-29,"23:58:22,636",INFO,org.apache.hadoop.metrics2.impl.MetricsSystemImpl,Scheduled Metric snapshot period at 10 second(s).
5,6,2021-03-29,"23:58:22,636",INFO,org.apache.hadoop.metrics2.impl.MetricsSystemImpl,DataNode metrics system started
6,7,2021-03-29,"23:58:24,355",INFO,org.apache.hadoop.hdfs.server.common.Util,dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
7,8,2021-03-29,"23:58:24,705",INFO,org.apache.hadoop.hdfs.server.datanode.BlockScanner,Initialized block scanner with targetBytesPerSec 1048576
8,9,2021-03-29,"23:58:24,777",INFO,org.apache.hadoop.hdfs.server.datanode.DataNode,Configured hostname is hadoop-slave2
9,10,2021-03-29,"23:58:24,778",INFO,org.apache.hadoop.hdfs.server.common.Util,dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
10,11,2021-03-29,"23:58:24,992",INFO,org.apache.hadoop.hdfs.server.datanode.DataNode,Starting DataNode with maxLockedMemory = 0
11,12,2021-03-29,"23:58:25,984",INFO,org.apache.hadoop.hdfs.server.datanode.DataNode,Opened streaming server at /0.0.0.0:9866
12,13,2021-03-29,"23:58:26,101",INFO,org.apache.hadoop.hdfs.server.datanode.DataNode,Balancing bandwidth is 10485760 bytes/s
13,14,2021-03-29,"23:58:26,102",INFO,org.apache.hadoop.hdfs.server.datanode.DataNode,Number threads for balancing is 50
14,15,2021-03-29,"23:58:27,925",INFO,org.eclipse.jetty.util.log,Logging initialized @40007ms
15,16,2021-03-29,"23:58:28,901",INFO,org.apache.hadoop.security.authentication.server.AuthenticationFilter,"Unable to initialize FileSignerSecretProvider, falling back to use random secrets."
16,17,2021-03-29,"23:58:28,930",INFO,org.apache.hadoop.http.HttpRequestLog,Http request log for http.requests.datanode is not defined
17,18,2021-03-29,"23:58:28,969",INFO,org.apache.hadoop.http.HttpServer2,Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
18,19,2021-03-29,"23:58:29,017",INFO,org.apache.hadoop.http.HttpServer2,Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
19,20,2021-03-29,"23:58:29,017",INFO,org.apache.hadoop.http.HttpServer2,Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
20,21,2021-03-29,"23:58:29,017",INFO,org.apache.hadoop.http.HttpServer2,Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
21,22,2021-03-29,"23:58:29,369",INFO,org.apache.hadoop.http.HttpServer2,Jetty bound to port 39353
22,23,2021-03-29,"23:58:29,386",INFO,org.eclipse.jetty.server.Server,"jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827"
23,24,2021-03-29,"23:58:29,744",INFO,org.eclipse.jetty.server.handler.ContextHandler,"Started o.e.j.s.ServletContextHandler@269308cc{/logs,file:///usr/local/hadoop/logs/,AVAILABLE}"
24,25,2021-03-29,"23:58:29,757",INFO,org.eclipse.jetty.server.handler.ContextHandler,"Started o.e.j.s.ServletContextHandler@17d816b3{/static,file:///usr/local/hadoop/share/hadoop/hdfs/webapps/static/,AVAILABLE}"
25,26,2021-03-29,"23:58:30,744",INFO,org.eclipse.jetty.server.handler.ContextHandler,"Started o.e.j.w.WebAppContext@5c41b8d8{/,file:///usr/local/hadoop/share/hadoop/hdfs/webapps/datanode/,AVAILABLE}{/datanode}"
26,27,2021-03-29,"23:58:30,756",INFO,org.eclipse.jetty.server.AbstractConnector,"Started ServerConnector@28e48b65{HTTP/1.1,[http/1.1]}{localhost:39353}"
27,28,2021-03-29,"23:58:30,756",INFO,org.eclipse.jetty.server.Server,Started @42838ms
28,29,2021-03-29,"23:58:31,963",INFO,org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer,Listening HTTP traffic on /0.0.0.0:9864
29,30,2021-03-29,"23:58:32,038",INFO,org.apache.hadoop.hdfs.server.datanode.DataNode,dnUserName = root
30,31,2021-03-29,"23:58:32,039",INFO,org.apache.hadoop.hdfs.server.datanode.DataNode,supergroup = supergroup
31,32,2021-03-29,"23:58:32,042",INFO,org.apache.hadoop.util.JvmPauseMonitor,Starting JVM pause monitor
32,33,2021-03-29,"23:58:32,424",INFO,org.apache.hadoop.ipc.CallQueueManager,"Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false."
33,34,2021-03-29,"23:58:32,890",INFO,org.apache.hadoop.ipc.Server,Starting Socket Reader #1 for port 9867
34,35,2021-03-29,"23:58:37,022",INFO,org.apache.hadoop.hdfs.server.datanode.DataNode,Opened IPC server at /0.0.0.0:9867
35,36,2021-03-29,"23:58:37,367",INFO,org.apache.hadoop.hdfs.server.datanode.DataNode,Refresh request received for nameservices: null
36,37,2021-03-29,"23:58:37,456",INFO,org.apache.hadoop.hdfs.server.datanode.DataNode,Starting BPOfferServices for nameservices: <default>
37,38,2021-03-29,"23:58:38,038",INFO,org.apache.hadoop.hdfs.server.datanode.DataNode,Block pool <registering> (Datanode Uuid unassigned) service to hadoop-master/172.18.0.3:9000 starting to offer service
38,39,2021-03-29,"23:58:38,242",INFO,org.apache.hadoop.ipc.Server,IPC Server Responder: starting
39,40,2021-03-29,"23:58:38,259",INFO,org.apache.hadoop.ipc.Server,IPC Server listener on 9867: starting
40,41,2021-03-29,"23:58:41,001",INFO,org.apache.hadoop.ipc.Client,"Retrying connect to server: hadoop-master/172.18.0.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)"
41,42,2021-03-29,"23:58:42,002",INFO,org.apache.hadoop.ipc.Client,"Retrying connect to server: hadoop-master/172.18.0.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)"
42,43,2021-03-29,"23:58:43,021",INFO,org.apache.hadoop.ipc.Client,"Retrying connect to server: hadoop-master/172.18.0.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)"
43,44,2021-03-29,"23:58:44,032",INFO,org.apache.hadoop.ipc.Client,"Retrying connect to server: hadoop-master/172.18.0.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)"
44,45,2021-03-29,"23:58:45,039",INFO,org.apache.hadoop.ipc.Client,"Retrying connect to server: hadoop-master/172.18.0.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)"
45,46,2021-03-29,"23:58:45,775",WARN,org.apache.hadoop.hdfs.server.datanode.DataNode,"Block pool ID needed, but service not yet registered with NN, trace:"
46,47,2021-03-29,"23:58:45,825",WARN,org.apache.hadoop.hdfs.server.datanode.DataNode,"Block pool ID needed, but service not yet registered with NN, trace:"
47,48,2021-03-29,"23:58:45,834",ERROR,org.apache.hadoop.jmx.JMXJsonServlet,"getting attribute VolumeInfo of Hadoop:service=DataNode,name=DataNodeInfo threw an exception"
48,49,2021-03-29,"23:58:46,071",INFO,org.apache.hadoop.ipc.Client,"Retrying connect to server: hadoop-master/172.18.0.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)"
49,50,2021-03-29,"23:58:47,118",INFO,org.apache.hadoop.ipc.Client,"Retrying connect to server: hadoop-master/172.18.0.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)"
50,51,2021-03-29,"23:58:48,162",INFO,org.apache.hadoop.ipc.Client,"Retrying connect to server: hadoop-master/172.18.0.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)"
51,52,2021-03-29,"23:58:49,163",INFO,org.apache.hadoop.ipc.Client,"Retrying connect to server: hadoop-master/172.18.0.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)"
52,53,2021-03-29,"23:58:50,165",INFO,org.apache.hadoop.ipc.Client,"Retrying connect to server: hadoop-master/172.18.0.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)"
53,54,2021-03-29,"23:58:50,169",WARN,org.apache.hadoop.hdfs.server.datanode.DataNode,Problem connecting to server: hadoop-master/172.18.0.3:9000
54,55,2021-03-29,"23:58:55,015",WARN,org.apache.hadoop.hdfs.server.datanode.DataNode,"Block pool ID needed, but service not yet registered with NN, trace:"
55,56,2021-03-29,"23:58:55,016",WARN,org.apache.hadoop.hdfs.server.datanode.DataNode,"Block pool ID needed, but service not yet registered with NN, trace:"
56,57,2021-03-29,"23:58:55,017",ERROR,org.apache.hadoop.jmx.JMXJsonServlet,"getting attribute VolumeInfo of Hadoop:service=DataNode,name=DataNodeInfo threw an exception"
57,58,2021-03-29,"23:58:56,257",INFO,org.apache.hadoop.ipc.Client,"Retrying connect to server: hadoop-master/172.18.0.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)"
58,59,2021-03-29,"23:58:57,260",INFO,org.apache.hadoop.ipc.Client,"Retrying connect to server: hadoop-master/172.18.0.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)"
59,60,2021-03-29,"23:58:58,271",INFO,org.apache.hadoop.ipc.Client,"Retrying connect to server: hadoop-master/172.18.0.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)"
60,61,2021-03-29,"23:58:59,279",INFO,org.apache.hadoop.ipc.Client,"Retrying connect to server: hadoop-master/172.18.0.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)"
61,62,2021-03-29,"23:59:00,280",INFO,org.apache.hadoop.ipc.Client,"Retrying connect to server: hadoop-master/172.18.0.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)"
62,63,2021-03-29,"23:59:01,169",WARN,org.apache.hadoop.hdfs.server.datanode.DataNode,"Block pool ID needed, but service not yet registered with NN, trace:"
63,64,2021-03-29,"23:59:01,171",WARN,org.apache.hadoop.hdfs.server.datanode.DataNode,"Block pool ID needed, but service not yet registered with NN, trace:"
64,65,2021-03-29,"23:59:01,171",ERROR,org.apache.hadoop.jmx.JMXJsonServlet,"getting attribute VolumeInfo of Hadoop:service=DataNode,name=DataNodeInfo threw an exception"
65,66,2021-03-29,"23:59:01,312",INFO,org.apache.hadoop.ipc.Client,"Retrying connect to server: hadoop-master/172.18.0.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)"
66,67,2021-03-29,"23:59:02,314",INFO,org.apache.hadoop.ipc.Client,"Retrying connect to server: hadoop-master/172.18.0.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)"
67,68,2021-03-29,"23:59:03,318",INFO,org.apache.hadoop.ipc.Client,"Retrying connect to server: hadoop-master/172.18.0.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)"
68,69,2021-03-29,"23:59:04,320",INFO,org.apache.hadoop.ipc.Client,"Retrying connect to server: hadoop-master/172.18.0.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)"
69,70,2021-03-29,"23:59:08,043",WARN,org.apache.hadoop.hdfs.server.datanode.DataNode,"Block pool ID needed, but service not yet registered with NN, trace:"
70,71,2021-03-29,"23:59:08,045",WARN,org.apache.hadoop.hdfs.server.datanode.DataNode,"Block pool ID needed, but service not yet registered with NN, trace:"
71,72,2021-03-29,"23:59:08,071",ERROR,org.apache.hadoop.jmx.JMXJsonServlet,"getting attribute VolumeInfo of Hadoop:service=DataNode,name=DataNodeInfo threw an exception"
72,73,2021-03-29,"23:59:12,711",INFO,org.apache.hadoop.hdfs.server.datanode.DataNode,Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to hadoop-master/172.18.0.3:9000
73,74,2021-03-29,"23:59:12,726",INFO,org.apache.hadoop.hdfs.server.common.Storage,"Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)"
74,75,2021-03-29,"23:59:12,816",INFO,org.apache.hadoop.hdfs.server.common.Storage,Lock on /home/hadoop3/hadoop/tmp/dfs/data/in_use.lock acquired by nodename 98@hadoop-slave2
75,76,2021-03-29,"23:59:12,819",INFO,org.apache.hadoop.hdfs.server.common.Storage,Storage directory with location [DISK]file:/home/hadoop3/hadoop/tmp/dfs/data is not formatted for namespace 1745262111. Formatting...
76,77,2021-03-29,"23:59:12,821",INFO,org.apache.hadoop.hdfs.server.common.Storage,Generated new storageID DS-ddb6f1bb-2764-4575-b2a3-b3c58a4d6a5e for directory /home/hadoop3/hadoop/tmp/dfs/data
77,78,2021-03-29,"23:59:12,909",INFO,org.apache.hadoop.hdfs.server.common.Storage,Analyzing storage directories for bpid BP-23028314-172.17.0.2-1615261831501
78,79,2021-03-29,"23:59:12,909",INFO,org.apache.hadoop.hdfs.server.common.Storage,Locking is disabled for /home/hadoop3/hadoop/tmp/dfs/data/current/BP-23028314-172.17.0.2-1615261831501
79,80,2021-03-29,"23:59:12,911",INFO,org.apache.hadoop.hdfs.server.common.Storage,Block pool storage directory for location [DISK]file:/home/hadoop3/hadoop/tmp/dfs/data and block pool id BP-23028314-172.17.0.2-1615261831501 is not formatted. Formatting ...
80,81,2021-03-29,"23:59:12,911",INFO,org.apache.hadoop.hdfs.server.common.Storage,Formatting block pool BP-23028314-172.17.0.2-1615261831501 directory /home/hadoop3/hadoop/tmp/dfs/data/current/BP-23028314-172.17.0.2-1615261831501/current
81,82,2021-03-29,"23:59:13,013",INFO,org.apache.hadoop.hdfs.server.datanode.DataNode,Setting up storage: nsid=1745262111;bpid=BP-23028314-172.17.0.2-1615261831501;lv=-57;nsInfo=lv=-65;cid=CID-5d2d06ad-4f9e-4a75-bca5-3151ff84f93a;nsid=1745262111;c=1615261831501;bpid=BP-23028314-172.17.0.2-1615261831501;dnuuid=null
82,83,2021-03-29,"23:59:13,034",INFO,org.apache.hadoop.hdfs.server.datanode.DataNode,Generated and persisted new Datanode UUID 96f4f935-6692-413a-8fa2-c552a67516b3
83,84,2021-03-29,"23:59:14,955",ERROR,org.apache.hadoop.jmx.JMXJsonServlet,"getting attribute VolumeInfo of Hadoop:service=DataNode,name=DataNodeInfo threw an exception"
84,85,2021-03-29,"23:59:16,194",INFO,org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl,Added new volume: DS-ddb6f1bb-2764-4575-b2a3-b3c58a4d6a5e
85,86,2021-03-29,"23:59:16,194",INFO,org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl,"Added volume - [DISK]file:/home/hadoop3/hadoop/tmp/dfs/data, StorageType: DISK"
86,87,2021-03-29,"23:59:16,235",INFO,org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl,Registered FSDatasetState MBean
87,88,2021-03-29,"23:59:16,283",INFO,org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker,Scheduling a check for /home/hadoop3/hadoop/tmp/dfs/data
88,89,2021-03-29,"23:59:16,579",INFO,org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker,Scheduled health check for volume /home/hadoop3/hadoop/tmp/dfs/data
89,90,2021-03-29,"23:59:16,686",INFO,org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl,Adding block pool BP-23028314-172.17.0.2-1615261831501
90,91,2021-03-29,"23:59:16,702",INFO,org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl,Scanning block pool BP-23028314-172.17.0.2-1615261831501 on volume /home/hadoop3/hadoop/tmp/dfs/data...
91,92,2021-03-29,"23:59:17,082",INFO,org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl,Time taken to scan block pool BP-23028314-172.17.0.2-1615261831501 on /home/hadoop3/hadoop/tmp/dfs/data: 379ms
92,93,2021-03-29,"23:59:17,083",INFO,org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl,Total time to scan all replicas for block pool BP-23028314-172.17.0.2-1615261831501: 397ms
93,94,2021-03-29,"23:59:17,103",INFO,org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl,Adding replicas to map for block pool BP-23028314-172.17.0.2-1615261831501 on volume /home/hadoop3/hadoop/tmp/dfs/data...
94,95,2021-03-29,"23:59:17,104",INFO,org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice,Replica Cache file: /home/hadoop3/hadoop/tmp/dfs/data/current/BP-23028314-172.17.0.2-1615261831501/current/replicas doesn't exist
95,96,2021-03-29,"23:59:17,147",INFO,org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl,Time to add replicas to map for block pool BP-23028314-172.17.0.2-1615261831501 on volume /home/hadoop3/hadoop/tmp/dfs/data: 44ms
96,97,2021-03-29,"23:59:17,153",INFO,org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl,Total time to add all replicas to map for block pool BP-23028314-172.17.0.2-1615261831501: 67ms
97,98,2021-03-29,"23:59:17,267",INFO,org.apache.hadoop.hdfs.server.datanode.VolumeScanner,Now scanning bpid BP-23028314-172.17.0.2-1615261831501 on volume /home/hadoop3/hadoop/tmp/dfs/data
98,99,2021-03-29,"23:59:17,271",INFO,org.apache.hadoop.hdfs.server.datanode.VolumeScanner,"VolumeScanner(/home/hadoop3/hadoop/tmp/dfs/data, DS-ddb6f1bb-2764-4575-b2a3-b3c58a4d6a5e): finished scanning block pool BP-23028314-172.17.0.2-1615261831501"
99,100,2021-03-29,"23:59:17,300",INFO,org.apache.hadoop.hdfs.server.datanode.VolumeScanner,"VolumeScanner(/home/hadoop3/hadoop/tmp/dfs/data, DS-ddb6f1bb-2764-4575-b2a3-b3c58a4d6a5e): no suitable block pools found to scan.  Waiting 1814399966 ms."
100,101,2021-03-29,"23:59:17,584",INFO,org.apache.hadoop.hdfs.server.datanode.DirectoryScanner,Periodic Directory Tree Verification scan starting at 3/30/21 1:17 AM with interval of 21600000ms
101,102,2021-03-29,"23:59:17,734",INFO,org.apache.hadoop.hdfs.server.datanode.DataNode,Block pool BP-23028314-172.17.0.2-1615261831501 (Datanode Uuid 96f4f935-6692-413a-8fa2-c552a67516b3) service to hadoop-master/172.18.0.3:9000 beginning handshake with NN
102,103,2021-03-29,"23:59:18,024",INFO,org.apache.hadoop.hdfs.server.datanode.DataNode,Block pool Block pool BP-23028314-172.17.0.2-1615261831501 (Datanode Uuid 96f4f935-6692-413a-8fa2-c552a67516b3) service to hadoop-master/172.18.0.3:9000 successfully registered with NN
103,104,2021-03-29,"23:59:18,025",INFO,org.apache.hadoop.hdfs.server.datanode.DataNode,For namenode hadoop-master/172.18.0.3:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
104,105,2021-03-29,"23:59:18,830",INFO,org.apache.hadoop.hdfs.server.datanode.DataNode,"Successfully sent block report 0x60fdacd05da174d5,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 25 msec to generate and 405 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5."
105,106,2021-03-29,"23:59:18,835",INFO,org.apache.hadoop.hdfs.server.datanode.DataNode,Got finalize command for block pool BP-23028314-172.17.0.2-1615261831501
106,107,2021-03-30,"00:00:49,211",INFO,org.apache.hadoop.hdfs.server.datanode.DataNode,Receiving BP-23028314-172.17.0.2-1615261831501:blk_1073741825_1001 src: /172.18.0.3:43966 dest: /172.18.0.4:9866
107,108,2021-03-30,"00:00:49,346",INFO,org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient,"SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false"
108,109,2021-03-30,"00:00:50,183",INFO,org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace,"src: /172.18.0.3:43966, dest: /172.18.0.4:9866, bytes: 13, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_523782650_1, offset: 0, srvID: 96f4f935-6692-413a-8fa2-c552a67516b3, blockid: BP-23028314-172.17.0.2-1615261831501:blk_1073741825_1001, duration(ns): 128870871"
109,110,2021-03-30,"00:00:50,183",INFO,org.apache.hadoop.hdfs.server.datanode.DataNode,"PacketResponder: BP-23028314-172.17.0.2-1615261831501:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[172.18.0.2:9866] terminating"
110,111,2021-03-30,"00:00:50,911",INFO,org.apache.hadoop.hdfs.server.datanode.DataNode,Receiving BP-23028314-172.17.0.2-1615261831501:blk_1073741826_1002 src: /172.18.0.2:55690 dest: /172.18.0.4:9866
111,112,2021-03-30,"00:00:50,945",INFO,org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace,"src: /172.18.0.2:55690, dest: /172.18.0.4:9866, bytes: 13, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_523782650_1, offset: 0, srvID: 96f4f935-6692-413a-8fa2-c552a67516b3, blockid: BP-23028314-172.17.0.2-1615261831501:blk_1073741826_1002, duration(ns): 14105728"
112,113,2021-03-30,"00:00:50,954",INFO,org.apache.hadoop.hdfs.server.datanode.DataNode,"PacketResponder: BP-23028314-172.17.0.2-1615261831501:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating"
113,114,2021-03-30,"00:00:57,290",INFO,org.apache.hadoop.hdfs.server.datanode.DataNode,Receiving BP-23028314-172.17.0.2-1615261831501:blk_1073741827_1003 src: /172.18.0.3:37978 dest: /172.18.0.4:9866
114,115,2021-03-30,"00:00:57,292",INFO,org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient,"SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false"
115,116,2021-03-30,"00:00:57,458",INFO,org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace,"src: /172.18.0.3:37978, dest: /172.18.0.4:9866, bytes: 317057, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-562512649_1, offset: 0, srvID: 96f4f935-6692-413a-8fa2-c552a67516b3, blockid: BP-23028314-172.17.0.2-1615261831501:blk_1073741827_1003, duration(ns): 149834717"
116,117,2021-03-30,"00:00:57,458",INFO,org.apache.hadoop.hdfs.server.datanode.DataNode,"PacketResponder: BP-23028314-172.17.0.2-1615261831501:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[172.18.0.2:9866] terminating"
117,118,2021-03-30,"00:00:58,002",INFO,org.apache.hadoop.hdfs.server.datanode.DataNode,Receiving BP-23028314-172.17.0.2-1615261831501:blk_1073741828_1004 src: /172.18.0.2:48014 dest: /172.18.0.4:9866
118,119,2021-03-30,"00:00:58,051",INFO,org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace,"src: /172.18.0.2:48014, dest: /172.18.0.4:9866, bytes: 239, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-562512649_1, offset: 0, srvID: 96f4f935-6692-413a-8fa2-c552a67516b3, blockid: BP-23028314-172.17.0.2-1615261831501:blk_1073741828_1004, duration(ns): 45147942"
119,120,2021-03-30,"00:00:58,051",INFO,org.apache.hadoop.hdfs.server.datanode.DataNode,"PacketResponder: BP-23028314-172.17.0.2-1615261831501:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating"
120,121,2021-03-30,"00:00:58,627",INFO,org.apache.hadoop.hdfs.server.datanode.DataNode,Receiving BP-23028314-172.17.0.2-1615261831501:blk_1073741829_1005 src: /172.18.0.2:49932 dest: /172.18.0.4:9866
121,122,2021-03-30,"00:00:58,680",INFO,org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace,"src: /172.18.0.2:49932, dest: /172.18.0.4:9866, bytes: 72, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-562512649_1, offset: 0, srvID: 96f4f935-6692-413a-8fa2-c552a67516b3, blockid: BP-23028314-172.17.0.2-1615261831501:blk_1073741829_1005, duration(ns): 48045929"
122,123,2021-03-30,"00:00:58,680",INFO,org.apache.hadoop.hdfs.server.datanode.DataNode,"PacketResponder: BP-23028314-172.17.0.2-1615261831501:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating"
123,124,2021-03-30,"00:00:59,432",INFO,org.apache.hadoop.hdfs.server.datanode.DataNode,Receiving BP-23028314-172.17.0.2-1615261831501:blk_1073741830_1006 src: /172.18.0.2:51522 dest: /172.18.0.4:9866
124,125,2021-03-30,"00:00:59,557",INFO,org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace,"src: /172.18.0.2:51522, dest: /172.18.0.4:9866, bytes: 192930, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-562512649_1, offset: 0, srvID: 96f4f935-6692-413a-8fa2-c552a67516b3, blockid: BP-23028314-172.17.0.2-1615261831501:blk_1073741830_1006, duration(ns): 117838502"
125,126,2021-03-30,"00:00:59,558",INFO,org.apache.hadoop.hdfs.server.datanode.DataNode,"PacketResponder: BP-23028314-172.17.0.2-1615261831501:blk_1073741830_1006, type=LAST_IN_PIPELINE terminating"
126,127,2021-03-30,"00:01:30,099",INFO,org.apache.hadoop.hdfs.server.datanode.DataNode,Receiving BP-23028314-172.17.0.2-1615261831501:blk_1073741831_1007 src: /172.18.0.2:37588 dest: /172.18.0.4:9866
127,128,2021-03-30,"00:01:30,206",INFO,org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace,"src: /172.18.0.2:37588, dest: /172.18.0.4:9866, bytes: 223541, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1509079730_1, offset: 0, srvID: 96f4f935-6692-413a-8fa2-c552a67516b3, blockid: BP-23028314-172.17.0.2-1615261831501:blk_1073741831_1007, duration(ns): 60644012"
128,129,2021-03-30,"00:01:30,207",INFO,org.apache.hadoop.hdfs.server.datanode.DataNode,"PacketResponder: BP-23028314-172.17.0.2-1615261831501:blk_1073741831_1007, type=LAST_IN_PIPELINE terminating"
129,130,2021-03-30,"00:01:42,651",INFO,org.apache.hadoop.hdfs.server.datanode.DataNode,Receiving BP-23028314-172.17.0.2-1615261831501:blk_1073741832_1008 src: /172.18.0.2:47028 dest: /172.18.0.4:9866
130,131,2021-03-30,"00:02:00,471",INFO,org.apache.hadoop.hdfs.server.datanode.DataNode,Receiving BP-23028314-172.17.0.2-1615261831501:blk_1073741833_1009 src: /172.18.0.4:36742 dest: /172.18.0.4:9866
131,132,2021-03-30,"00:02:00,478",INFO,org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient,"SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false"
132,133,2021-03-30,"00:02:00,599",INFO,org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace,"src: /172.18.0.4:36742, dest: /172.18.0.4:9866, bytes: 26, op: HDFS_WRITE, cliID: DFSClient_attempt_1617062369629_0001_r_000000_0_-996629036_1, offset: 0, srvID: 96f4f935-6692-413a-8fa2-c552a67516b3, blockid: BP-23028314-172.17.0.2-1615261831501:blk_1073741833_1009, duration(ns): 87684691"
133,134,2021-03-30,"00:02:00,599",INFO,org.apache.hadoop.hdfs.server.datanode.DataNode,"PacketResponder: BP-23028314-172.17.0.2-1615261831501:blk_1073741833_1009, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[172.18.0.2:9866] terminating"
134,135,2021-03-30,"00:02:03,434",INFO,org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace,"src: /172.18.0.2:47028, dest: /172.18.0.4:9866, bytes: 26621, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1509079730_1, offset: 0, srvID: 96f4f935-6692-413a-8fa2-c552a67516b3, blockid: BP-23028314-172.17.0.2-1615261831501:blk_1073741832_1008, duration(ns): 20768034769"
135,136,2021-03-30,"00:02:03,435",INFO,org.apache.hadoop.hdfs.server.datanode.DataNode,"PacketResponder: BP-23028314-172.17.0.2-1615261831501:blk_1073741832_1008, type=LAST_IN_PIPELINE terminating"
136,137,2021-03-30,"00:02:03,727",INFO,org.apache.hadoop.hdfs.server.datanode.DataNode,Receiving BP-23028314-172.17.0.2-1615261831501:blk_1073741834_1010 src: /172.18.0.2:49088 dest: /172.18.0.4:9866
137,138,2021-03-30,"00:02:03,759",INFO,org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace,"src: /172.18.0.2:49088, dest: /172.18.0.4:9866, bytes: 441, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1509079730_1, offset: 0, srvID: 96f4f935-6692-413a-8fa2-c552a67516b3, blockid: BP-23028314-172.17.0.2-1615261831501:blk_1073741834_1010, duration(ns): 24657256"
138,139,2021-03-30,"00:02:03,760",INFO,org.apache.hadoop.hdfs.server.datanode.DataNode,"PacketResponder: BP-23028314-172.17.0.2-1615261831501:blk_1073741834_1010, type=LAST_IN_PIPELINE terminating"
139,140,2021-03-30,"00:02:04,610",INFO,org.apache.hadoop.hdfs.server.datanode.DataNode,Receiving BP-23028314-172.17.0.2-1615261831501:blk_1073741835_1011 src: /172.18.0.2:51388 dest: /172.18.0.4:9866
140,141,2021-03-30,"00:02:04,729",INFO,org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace,"src: /172.18.0.2:51388, dest: /172.18.0.4:9866, bytes: 26621, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1509079730_1, offset: 0, srvID: 96f4f935-6692-413a-8fa2-c552a67516b3, blockid: BP-23028314-172.17.0.2-1615261831501:blk_1073741835_1011, duration(ns): 112004024"
141,142,2021-03-30,"00:02:04,729",INFO,org.apache.hadoop.hdfs.server.datanode.DataNode,"PacketResponder: BP-23028314-172.17.0.2-1615261831501:blk_1073741835_1011, type=LAST_IN_PIPELINE terminating"
142,143,2021-03-30,"00:02:05,132",INFO,org.apache.hadoop.hdfs.server.datanode.DataNode,Receiving BP-23028314-172.17.0.2-1615261831501:blk_1073741836_1012 src: /172.18.0.2:52860 dest: /172.18.0.4:9866
143,144,2021-03-30,"00:02:05,246",INFO,org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace,"src: /172.18.0.2:52860, dest: /172.18.0.4:9866, bytes: 223541, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1509079730_1, offset: 0, srvID: 96f4f935-6692-413a-8fa2-c552a67516b3, blockid: BP-23028314-172.17.0.2-1615261831501:blk_1073741836_1012, duration(ns): 110318525"
144,145,2021-03-30,"00:02:05,246",INFO,org.apache.hadoop.hdfs.server.datanode.DataNode,"PacketResponder: BP-23028314-172.17.0.2-1615261831501:blk_1073741836_1012, type=LAST_IN_PIPELINE terminating"
145,146,2021-03-30,"00:02:12,438",INFO,org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService,"Scheduling blk_1073741827_1003 replica FinalizedReplica, blk_1073741827_1003, FINALIZED"
146,147,2021-03-30,"00:02:12,488",INFO,org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService,"Scheduling blk_1073741828_1004 replica FinalizedReplica, blk_1073741828_1004, FINALIZED"
147,148,2021-03-30,"00:02:12,490",INFO,org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService,"Scheduling blk_1073741829_1005 replica FinalizedReplica, blk_1073741829_1005, FINALIZED"
148,149,2021-03-30,"00:02:12,491",INFO,org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService,"Scheduling blk_1073741830_1006 replica FinalizedReplica, blk_1073741830_1006, FINALIZED"
149,150,2021-03-30,"00:02:12,491",INFO,org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService,"Scheduling blk_1073741831_1007 replica FinalizedReplica, blk_1073741831_1007, FINALIZED"
150,151,2021-03-30,"00:02:12,491",INFO,org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService,"Scheduling blk_1073741832_1008 replica FinalizedReplica, blk_1073741832_1008, FINALIZED"
151,152,2021-03-30,"00:02:12,494",INFO,org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService,Deleted BP-23028314-172.17.0.2-1615261831501 blk_1073741827_1003 URI file:/home/hadoop3/hadoop/tmp/dfs/data/current/BP-23028314-172.17.0.2-1615261831501/current/finalized/subdir0/subdir0/blk_1073741827
152,153,2021-03-30,"00:02:12,515",INFO,org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService,Deleted BP-23028314-172.17.0.2-1615261831501 blk_1073741828_1004 URI file:/home/hadoop3/hadoop/tmp/dfs/data/current/BP-23028314-172.17.0.2-1615261831501/current/finalized/subdir0/subdir0/blk_1073741828
153,154,2021-03-30,"00:02:12,515",INFO,org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService,Deleted BP-23028314-172.17.0.2-1615261831501 blk_1073741829_1005 URI file:/home/hadoop3/hadoop/tmp/dfs/data/current/BP-23028314-172.17.0.2-1615261831501/current/finalized/subdir0/subdir0/blk_1073741829
154,155,2021-03-30,"00:02:12,515",INFO,org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService,Deleted BP-23028314-172.17.0.2-1615261831501 blk_1073741830_1006 URI file:/home/hadoop3/hadoop/tmp/dfs/data/current/BP-23028314-172.17.0.2-1615261831501/current/finalized/subdir0/subdir0/blk_1073741830
155,156,2021-03-30,"00:02:12,516",INFO,org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService,Deleted BP-23028314-172.17.0.2-1615261831501 blk_1073741831_1007 URI file:/home/hadoop3/hadoop/tmp/dfs/data/current/BP-23028314-172.17.0.2-1615261831501/current/finalized/subdir0/subdir0/blk_1073741831
156,157,2021-03-30,"00:02:12,517",INFO,org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService,Deleted BP-23028314-172.17.0.2-1615261831501 blk_1073741832_1008 URI file:/home/hadoop3/hadoop/tmp/dfs/data/current/BP-23028314-172.17.0.2-1615261831501/current/finalized/subdir0/subdir0/blk_1073741832
157,158,2021-03-30,"00:02:35,163",WARN,org.apache.hadoop.util.JvmPauseMonitor,Detected pause in JVM or host machine (eg GC): pause of approximately 11045ms
158,159,GC,pool,'PS,MarkSweep' had collection(s),count=1 time=8270ms
159,160,GC,pool,'PS,Scavenge' had collection(s),count=1 time=2680ms
